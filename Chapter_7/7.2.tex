\documentclass[../main.tex]{subfiles}
\begin{document}

首先讨论假设检验中的两类错误。若原假设为真，但拒绝了原假设，则犯了\emph{第 I 类错误}，又称\emph{弃真错误}。若原假设为假，但不拒绝原假设，则犯了\emph{第 II 类错误}，又称\emph{取伪错误}。两类错误发生的概率分别记作 $P_\theta(\text I)(\theta\in\Theta_0)$ 和 $P_\theta(\text{II})(\theta\in\Theta_1)$。一次决策不会同时犯两种错误。

根据样本作决策，错误不可能根本避免。对于固定的 $n$，调整检验准则时，两种错误发生的概率此消彼长。

\begin{example}
    检验元件是否合格，$H_0$ 和 $H_1$ 分别表示合格与不合格。
    \begin{enumerate}
        \item 若从不拒绝 $H_0$，即总认为元件合格，则 $P_\theta(\text I)=0$，但 $P_\theta(\text{II})=1$。
        \item 一般地，当 $P_\theta(\text I)$ 变小，就意味着我们更不容易拒绝原假设（更谨慎地判断元件不合格），此时不合格元件就更不容易检出，因此 $P_\theta(\text{II})$ 变大。
    \end{enumerate}
\end{example}

进一步讨论两种错误的概率。对于 $\theta\in\Theta_0$，我们有 $P_\theta(\text I)=P_\theta((X_1,\cdots,X_n)\in R)$，将其记为 $\alpha(R)$，即调整拒绝域时，犯第 I 类错误的概率相应变化。对于 $\theta\in\Theta_1$，我们有 $P_\theta(\text{II})=P_\theta((X_1,\cdots,X_n)\in R^c)$，将其记为 $\beta(R)$，即调整拒绝域时，犯第 II 类错误的概率相应变化。若固定 $R$，则 $\alpha(R)$ 和 $\beta(R)$ 都是 $\theta$ 的函数。对于 $\theta\in\Theta_1$，我们将 $(1-\beta(R))$ 称为\emph{功效}（Power）。

利用上述概念，我们之前所做的假设检验“当 $T(X_1,\cdots,X_n)\geq c$ 时拒绝 $H_0$”需要满足的条件 $P_{H_0}(T(X_1,\cdots,X_n)\geq c)\leq\alpha$ 实际上就是犯第 I 类错误的概率不超过 $\alpha$。

在假设检验中，有所谓 \emph{Neyman-Pearson 范式}：固定 $n$，对于预先给定的检验水平 $\alpha\in(0,1)$，首先保证犯第 I 类错误的概率不超过 $\alpha$，再在此限制之下使 $P_\theta(\text{II})(\theta\in\Theta_1)$ 尽可能小。

此种范式下，$H_0$ 与 $H_1$ 一般来说地位不对等。原假设 $H_0$ 通常是受保护的，若证据不充分则不能予以拒绝；备择假设 $H_1$ 往往是我们真正感兴趣的，又称\emph{研究假设}。

\end{document}
